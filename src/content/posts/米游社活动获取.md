---
title: 米游社活动获取
published: 2024-09-10
description: '教学如何获取米游社最近的活动，整理打包'
image: ''
tags: [编程,米游社,示例]
category: 'python'
draft: false 
language: ''
---
主要使用了 **Selenium** 库，通过模拟浏览器操作从网页获取数据，并将数据生成一个简易的 HTML 页面。以下是代码的运行方式和各部分功能的介绍：

### 运行环境和准备工作
1. **安装依赖**：首先确保已安装了必要的库，包括 `selenium` 和 Chrome 的 WebDriver。
   - 通过命令行可以使用以下命令安装 `selenium`：
     ```bash
     pip install selenium
     ```
   - **Chrome WebDriver**：还需要下载与 Chrome 浏览器版本匹配的 [ChromeDriver](https://sites.google.com/a/chromium.org/chromedriver/) 并确保其路径可被系统识别。

2. **代码运行方式**：
   - 直接运行此 Python 脚本，Selenium 将自动打开 Chrome 浏览器，访问指定网页 `https://www.miyoushe.com/ys/home/28`，并抓取页面上的特定信息，如图片、标题、文本和时间。
   - 最后将抓取到的数据生成 HTML 文件并保存为 `cards.html`，运行后可以用浏览器打开该文件查看生成的卡片式内容。

### 功能介绍
1. **启动浏览器并访问网页**：
   ```python
   driver = webdriver.Chrome()
   url = "https://www.miyoushe.com/ys/home/28"
   driver.get(url)
   ```
   - 这部分代码使用 Selenium 启动一个 Chrome 浏览器实例，并访问指定 URL。

2. **等待页面加载**：
   ```python
   driver.implicitly_wait(10)
   ```
   - 通过 `implicitly_wait(10)` 设置隐式等待时间，最多等待 10 秒以确保页面内容加载完成。

3. **抓取数据**：
   - **查找包含 `data-src` 属性的元素（一般是图片链接）**：
     ```python
     data_src_elements = driver.find_elements(By.XPATH, '//*[@data-src]')
     ```
   - **查找包含 `title` 属性的元素（通常是标题）**：
     ```python
     title_elements = driver.find_elements(By.XPATH, '//*[@title]')
     ```
   - **查找 `class="text"` 的元素（一般是描述文本）**：
     ```python
     text_elements = driver.find_elements(By.XPATH, '//*[@class="text"]')
     ```
   - **查找 `class="time"` 的元素（通常是时间信息）**：
     ```python
     time_elements = driver.find_elements(By.XPATH, '//*[@class="time"]')
     ```

4. **提取内容并生成 HTML 文件**：
   - 通过 `.get_attribute()` 和 `.text` 获取所需的图片链接、标题、描述和时间，确保每个列表的长度相同。
   - 最终，使用一个 `for` 循环，将所有数据生成 HTML 代码块，并保存到 `cards.html` 文件中。
   
5. **关闭浏览器**：
   ```python
   driver.quit()
   ```
   - 任务完成后，通过 `driver.quit()` 关闭浏览器，释放资源。

### 最终效果
生成的 `cards.html` 文件将会展示一个简洁的页面，每个条目都有图片、标题、描述文本和时间，排版为卡片样式。每个卡片的基本结构如下：
```html
<div class="card">
    <img src="图片链接" alt="活动图片">
    <h3>标题</h3>
    <p>描述文本 | 时间</p>
</div>
```

### 完整代码如下
``` python
from selenium import webdriver
from selenium.webdriver.common.by import By

# 创建一个浏览器驱动程序，这里以Chrome为例
driver = webdriver.Chrome()

# 发送HTTP请求获取网页内容
url = "https://www.miyoushe.com/ys/home/28"
driver.get(url)

# 使用Selenium等待页面加载
driver.implicitly_wait(10)

# 查找包含data-src的元素
data_src_elements = driver.find_elements(By.XPATH, '//*[@data-src]')

# 查找包含title的元素
title_elements = driver.find_elements(By.XPATH, '//*[@title]')

# 查找包含class="text"的元素
text_elements = driver.find_elements(By.XPATH, '//*[@class="text"]')

# 查找包含时间的元素
time_elements = driver.find_elements(By.XPATH, '//*[@class="time"]')

# 得到data-src、title、text和时间的值
data_src_values = [element.get_attribute("data-src") for element in data_src_elements]
title_values = [element.get_attribute("title") for element in title_elements]
text_values = [element.text for element in text_elements]
time_values = [element.find_element(By.TAG_NAME, "span").text for element in time_elements]

# 确保所有列表的长度相同
min_len = min(len(data_src_values), len(title_values), len(text_values), len(time_values))
data_src_values = data_src_values[:min_len]
title_values = title_values[:min_len]
text_values = text_values[:min_len]
time_values = time_values[:min_len]

# 创建一个HTML文档
html_code = """
<!DOCTYPE html>
<html>
<head>
    <style>
        .card {
            display: inline-block;
            margin: 10px;
            width: 300px;
            vertical-align: top;
        }

        .card img {
            width: 100%;
        }

        .card h3 {
            text-align: center;
        }

        .card p {
            text-align: center;
        }
    </style>
</head>
<body>
"""

# 生成卡片
for title, data_src, text, time in zip(title_values, data_src_values, text_values, time_values):
    card = f"""
    <div class="card">
        <img src="{data_src}" alt="活动图片">
        <h3>{title}</h3>
        <p>{text} | {time}</p>
    </div>
    """
    html_code += card

# 关闭HTML文档
html_code += """
</body>
</html>
"""

# 保存HTML到文件
with open("cards.html", "w", encoding="utf-8") as file:
    file.write(html_code)

# 关闭浏览器
driver.quit()

```

### 注意事项
- 如果 `find_elements` 找不到元素，可能是因为页面的结构变化，建议使用开发者工具检查页面的实际 DOM 结构，以确认 XPath 是否正确。
- ChromeDriver 版本需要与本地的 Chrome 浏览器版本匹配，确保下载正确的版本。

### 总结
这段代码通过 Selenium 自动化从网页中提取特定内容，最终生成了一个简单的 HTML 文件。整个流程包括了启动浏览器、抓取内容、生成 HTML 文件并关闭浏览器，是一种自动化处理网页数据的有效方式。

---

### 免责声明

本代码仅用于学习和技术交流目的，使用过程中请遵守相关法律法规。请注意，使用 Selenium 等自动化工具访问网站时，可能会违反目标网站的使用条款或政策。若使用本代码对外部网站进行数据抓取，请事先获取网站的授权或许可。开发者对因使用本代码导致的任何法律后果不承担任何责任，用户需自行承担风险。

---

